{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sentiment analysis using Python"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Part-of-speech tagging is the process of converting a sentence, in the form of a list of words,\n",
    "into a list of tuples, where each tuple is of the form (word, tag). The tag is a part-of-speech\n",
    "tag, and signifies whether the word is a noun, adjective, verb, and so on.\n",
    "\n",
    "The main goal of this notebook is to identify if reviews of movies are positives or negatives."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Most of the taggers are trainable. They use a list of tagged sentences as their training data. With these training\n",
    "sentences, the tagger generates an internal model that will tell it how to tag a word. Other taggers\n",
    "use external data sources or match word patterns to choose a tag for a word.\n",
    "\n",
    "Here we will use UnigramTagger by giving it a list of tagged sentences at initialization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Pierre',\n",
       " 'Vinken',\n",
       " ',',\n",
       " '61',\n",
       " 'years',\n",
       " 'old',\n",
       " ',',\n",
       " 'will',\n",
       " 'join',\n",
       " 'the',\n",
       " 'board',\n",
       " 'as',\n",
       " 'a',\n",
       " 'nonexecutive',\n",
       " 'director',\n",
       " 'Nov.',\n",
       " '29',\n",
       " '.']"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.tag import UnigramTagger\n",
    "from nltk.corpus import treebank\n",
    "train_sents = treebank.tagged_sents()\n",
    "tagger = UnigramTagger(train_sents)\n",
    "treebank.sents()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Pierre', 'NNP'),\n",
       " ('Vinken', 'NNP'),\n",
       " (',', ','),\n",
       " ('61', 'CD'),\n",
       " ('years', 'NNS'),\n",
       " ('old', 'JJ'),\n",
       " (',', ','),\n",
       " ('will', 'MD'),\n",
       " ('join', 'VB'),\n",
       " ('the', 'DT'),\n",
       " ('board', 'NN'),\n",
       " ('as', 'IN'),\n",
       " ('a', 'DT'),\n",
       " ('nonexecutive', 'JJ'),\n",
       " ('director', 'NN'),\n",
       " ('Nov.', 'NNP'),\n",
       " ('29', 'CD'),\n",
       " ('.', '.')]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tagger.tag(treebank.sents()[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see the first sentence as a list of words, and can see how it is transformed by the tag() function into a list of tagged tokens."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To identify positivity or negativity of the reviews we will use *SentiWordNet*, a lexical resource for opinion mining.  *SentiWordNet* assigns to each synset of WordNet three sentiment scores: positivity, negativity, objectivity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.75"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.corpus import sentiwordnet as swn\n",
    "list(swn.senti_synsets('good', 'a'))[0].pos_score()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Processing the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We first have to process the reviews."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is a function that helps us replace words matching regular expressions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Do not hesistate to ask questions'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "replacement_patterns = [\n",
    "    (r'â€™', '\\''),\n",
    "    (r'won\\'t', 'will not'),\n",
    "    (r'can\\'t', 'cannot'),\n",
    "    (r'i\\'m', 'i am'),\n",
    "    (r'ain\\'t', 'is not'),\n",
    "    (r'(\\w+)\\'ll', '\\g<1> will'),\n",
    "    (r'(\\w+)n\\'t', '\\g<1> not'),\n",
    "    (r'(\\w+)\\'ve', '\\g<1> have'),\n",
    "    (r'(\\w+)\\'s', '\\g<1> is'),\n",
    "    (r'(\\w+)\\'re', '\\g<1> are'),\n",
    "    (r'(\\w+)\\'d', '\\g<1> would'),\n",
    "]\n",
    "\n",
    "class RegexpReplacer(object):\n",
    "    def __init__(self, patterns=replacement_patterns): \n",
    "        self.patterns = [(re.compile(regex), repl) for (regex, repl) in patterns]\n",
    "    def replace(self, text):\n",
    "        s = text\n",
    "        for (pattern, repl) in self.patterns:\n",
    "            s = re.sub(pattern, repl, s) \n",
    "        return s\n",
    "    \n",
    "\n",
    "replacer=RegexpReplacer()\n",
    "replacer.replace(\"Don't hesistate to ask questions\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "str"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "open_file = open('data/review_polarity/txt_sentoken/pos/cv000_29590.txt', 'r', encoding='utf-8')\n",
    "file_to_string = open_file.read()\n",
    "type(file_to_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "success , whether they're about superheroes ( batm\n",
      "success , whether they are about superheroes ( bat\n",
      "<class 'str'>\n"
     ]
    }
   ],
   "source": [
    "text_replaced = replacer.replace(file_to_string)\n",
    "\n",
    "print(file_to_string[50:100])\n",
    "print(text_replaced[50:100])\n",
    "print(type(text_replaced))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After replacing the words by regular expressions, we will tokenize the reviews in a list of sentences, and then in a list of words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "27"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer=nltk.data.load('tokenizers/punkt/english.pickle')\n",
    "sentences = tokenizer.tokenize(text_replaced)\n",
    "len(sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['films',\n",
       " 'adapted',\n",
       " 'from',\n",
       " 'comic',\n",
       " 'books',\n",
       " 'have',\n",
       " 'had',\n",
       " 'plenty',\n",
       " 'of',\n",
       " 'success',\n",
       " 'whether',\n",
       " 'they',\n",
       " 'are',\n",
       " 'about',\n",
       " 'superheroes',\n",
       " 'batman',\n",
       " 'superman',\n",
       " 'spawn',\n",
       " 'or',\n",
       " 'geared',\n",
       " 'toward',\n",
       " 'kids',\n",
       " 'casper',\n",
       " 'or',\n",
       " 'the',\n",
       " 'arthouse',\n",
       " 'crowd',\n",
       " 'ghost',\n",
       " 'world',\n",
       " 'but',\n",
       " 'there',\n",
       " 'is',\n",
       " 'never',\n",
       " 'really',\n",
       " 'been',\n",
       " 'a',\n",
       " 'comic',\n",
       " 'book',\n",
       " 'like',\n",
       " 'from',\n",
       " 'hell',\n",
       " 'before']"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.tokenize import RegexpTokenizer\n",
    "tokenizer=RegexpTokenizer(\"[\\w]+\")\n",
    "\n",
    "for i in range(len(sentences)):\n",
    "    sentences[i] = tokenizer.tokenize(sentences[i])\n",
    "sentences[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will now use the tagger trained earlier using the UnigramTagger to tag each word of all sentences."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('films', 'NNS'),\n",
       " ('adapted', 'VBD'),\n",
       " ('from', 'IN'),\n",
       " ('comic', None),\n",
       " ('books', 'NNS'),\n",
       " ('have', 'VBP'),\n",
       " ('had', 'VBD'),\n",
       " ('plenty', 'NN'),\n",
       " ('of', 'IN'),\n",
       " ('success', 'NN'),\n",
       " ('whether', 'IN'),\n",
       " ('they', 'PRP'),\n",
       " ('are', 'VBP'),\n",
       " ('about', 'IN'),\n",
       " ('superheroes', None),\n",
       " ('batman', None),\n",
       " ('superman', None),\n",
       " ('spawn', None),\n",
       " ('or', 'CC'),\n",
       " ('geared', None),\n",
       " ('toward', 'IN'),\n",
       " ('kids', 'NNS'),\n",
       " ('casper', None),\n",
       " ('or', 'CC'),\n",
       " ('the', 'DT'),\n",
       " ('arthouse', None),\n",
       " ('crowd', 'NN'),\n",
       " ('ghost', None),\n",
       " ('world', 'NN'),\n",
       " ('but', 'CC'),\n",
       " ('there', 'EX'),\n",
       " ('is', 'VBZ'),\n",
       " ('never', 'RB'),\n",
       " ('really', 'RB'),\n",
       " ('been', 'VBN'),\n",
       " ('a', 'DT'),\n",
       " ('comic', None),\n",
       " ('book', 'NN'),\n",
       " ('like', 'IN'),\n",
       " ('from', 'IN'),\n",
       " ('hell', None),\n",
       " ('before', 'IN')]"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tagged_sent = []\n",
    "for sentence in sentences:\n",
    "    tagged_sent.append(tagger.tag(sentence))\n",
    "tagged_sent[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The tags used by *SentiWordNet* are different than the tags of the UnigramTagger. For example, an adjectif is tagged as **_'JJ'_**  in our tagger and it is tagged as **_'a'_** in *SentiWordNet*.\n",
    "\n",
    "The function below allows us to get the 3 scores (positive, negative, objective) of a word by using a tuple *(word, tag)* as an argument.\n",
    "\n",
    "**(can be improved)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.0, 0.0, 1.0]\n"
     ]
    }
   ],
   "source": [
    "def word_scores(wordntag):\n",
    "    result = []\n",
    "    word, tag = wordntag\n",
    "    if(tag == 'JJ'):\n",
    "        if( len(list(swn.senti_synsets(word, 'a'))) != 0 ):\n",
    "            result.extend([list(swn.senti_synsets(word, 'a'))[0].pos_score(), list(swn.senti_synsets(word, 'a'))[0].neg_score(), list(swn.senti_synsets(word, 'a'))[0].obj_score()])\n",
    "        else:\n",
    "            result = [0.0, 0.0, 0.0]\n",
    "    elif (tag == 'NNS' or tag == 'NN'):\n",
    "        if( len(list(swn.senti_synsets(word, 'n'))) != 0 ):\n",
    "            result.extend([list(swn.senti_synsets(word, 'n'))[0].pos_score(), list(swn.senti_synsets(word, 'n'))[0].neg_score(), list(swn.senti_synsets(word, 'n'))[0].obj_score()])\n",
    "        else:\n",
    "            result = [0.0, 0.0, 0.0]\n",
    "    elif(tag == 'RB'):\n",
    "        if( len(list(swn.senti_synsets(word, 'r'))) != 0 ):\n",
    "            result.extend([list(swn.senti_synsets(word, 'r'))[0].pos_score(), list(swn.senti_synsets(word, 'r'))[0].neg_score(), list(swn.senti_synsets(word, 'r'))[0].obj_score()])\n",
    "        else:\n",
    "            result = [0.0, 0.0, 0.0]\n",
    "    else:\n",
    "        result = [0.0, 0.0, 0.0]\n",
    "    return result;\n",
    "\n",
    "print(word_scores(tagged_sent[0][0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We apply that function for every word of each sentence to get a list of scores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.0, 0.0, 1.0], [0.0, 0.0, 0.0], [0.0, 0.0, 0.0], [0.0, 0.0, 0.0], [0.0, 0.0, 1.0], [0.0, 0.0, 0.0], [0.0, 0.0, 0.0], [0.0, 0.375, 0.625], [0.0, 0.0, 0.0], [0.125, 0.0, 0.875], [0.0, 0.0, 0.0], [0.0, 0.0, 0.0], [0.0, 0.0, 0.0], [0.0, 0.0, 0.0], [0.0, 0.0, 0.0], [0.0, 0.0, 0.0], [0.0, 0.0, 0.0], [0.0, 0.0, 0.0], [0.0, 0.0, 0.0], [0.0, 0.0, 0.0], [0.0, 0.0, 0.0], [0.0, 0.0, 1.0], [0.0, 0.0, 0.0], [0.0, 0.0, 0.0], [0.0, 0.0, 0.0], [0.0, 0.0, 0.0], [0.0, 0.0, 1.0], [0.0, 0.0, 0.0], [0.0, 0.0, 1.0], [0.0, 0.0, 0.0], [0.0, 0.0, 0.0], [0.0, 0.0, 0.0], [0.0, 0.625, 0.375], [0.625, 0.0, 0.375], [0.0, 0.0, 0.0], [0.0, 0.0, 0.0], [0.0, 0.0, 0.0], [0.0, 0.0, 1.0], [0.0, 0.0, 0.0], [0.0, 0.0, 0.0], [0.0, 0.0, 0.0], [0.0, 0.0, 0.0]]\n"
     ]
    }
   ],
   "source": [
    "scores = []\n",
    "for sentence in tagged_sent:\n",
    "    list_scores = []\n",
    "    for word in sentence:\n",
    "        list_scores.append(word_scores(word))\n",
    "    scores.append(list_scores)\n",
    "print(scores[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scoring\n",
    "\n",
    "The question is now to determine how will we decide if a review is positive or negative."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**First approach : we decide based on majority**\n",
    "\n",
    "If the positive score is bigger than the negative one, then it is a positive review. Else it's a negative one."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's first sum the positive and negative scores for each sentence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.017857142857142856, 0.023809523809523808, 0.19642857142857142]"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum_score = []\n",
    "for list_score in scores:\n",
    "    pos, neg, obj = 0.0, 0.0, 0.0\n",
    "    for score in list_score:\n",
    "        pos += score[0]\n",
    "        neg += score[1]\n",
    "        obj += score[2]\n",
    "    if(len(list_score) != 0):\n",
    "        sum_score.append([pos/len(list_score), neg/len(list_score), obj/len(list_score)])\n",
    "    else:\n",
    "        sum_score.append([0.0, 0.0, 0.0])\n",
    "sum_score[0]        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then we sum the scores of all sentences to get the global score of the review."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.022104363763838723, 0.025550012719126575, 0.18265805224130563]\n"
     ]
    }
   ],
   "source": [
    "pos, neg, obj = 0.0, 0.0, 0.0\n",
    "for score in sum_score:\n",
    "    pos += score[0]\n",
    "    neg += score[1]\n",
    "    obj += score[2]\n",
    "pos /= len(sum_score)\n",
    "neg /= len(sum_score)\n",
    "obj /= len(sum_score)\n",
    "print([pos, neg, obj])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creating a function that does the whole process for a text put in argument."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.022104363763838723, 0.025550012719126575, 0.18265805224130563]"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def sumScores(file):\n",
    "    open_file = open(file, 'r', encoding='utf-8')\n",
    "    file_to_string = open_file.read()\n",
    "    \n",
    "    text_replaced = replacer.replace(file_to_string)\n",
    "    \n",
    "    tokenizer=nltk.data.load('tokenizers/punkt/english.pickle')\n",
    "    sentences = tokenizer.tokenize(text_replaced)\n",
    "    \n",
    "    from nltk.tokenize import RegexpTokenizer\n",
    "    tokenizer=RegexpTokenizer(\"[\\w]+\")\n",
    "\n",
    "    for i in range(len(sentences)):\n",
    "        sentences[i] = tokenizer.tokenize(sentences[i])\n",
    "        \n",
    "    tagged_sent = []\n",
    "    for sentence in sentences:\n",
    "        tagged_sent.append(tagger.tag(sentence))\n",
    "        \n",
    "    scores = []\n",
    "    for sentence in tagged_sent:\n",
    "        list_scores = []\n",
    "        for word in sentence:\n",
    "            list_scores.append(word_scores(word))\n",
    "        scores.append(list_scores)\n",
    "        \n",
    "    sum_score = []\n",
    "    for list_score in scores:\n",
    "        pos, neg, obj = 0.0, 0.0, 0.0\n",
    "        for score in list_score:\n",
    "            pos += score[0]\n",
    "            neg += score[1]\n",
    "            obj += score[2]\n",
    "        if(len(list_score) != 0):\n",
    "            sum_score.append([pos/len(list_score), neg/len(list_score), obj/len(list_score)])\n",
    "        else:\n",
    "            sum_score.append([0.0, 0.0, 0.0])\n",
    "        \n",
    "    pos, neg, obj = 0.0, 0.0, 0.0\n",
    "    for score in sum_score:\n",
    "        pos += score[0]\n",
    "        neg += score[1]\n",
    "        obj += score[2]\n",
    "    if(len(sum_score) != 0):\n",
    "        pos /= len(sum_score)\n",
    "        neg /= len(sum_score)\n",
    "        obj /= len(sum_score)\n",
    "    return([pos, neg, obj])\n",
    "    \n",
    "sumScores('data/review_polarity/txt_sentoken/pos/cv000_29590.txt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's try that scoring technique on all positive reviews and see how it performs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "pos_reviews = os.listdir('data/review_polarity/txt_sentoken/pos')\n",
    "neg_reviews = os.listdir('data/review_polarity/txt_sentoken/pos')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__First decision :__ We choose the highest value (between neg and pos) to determine if a review is positive or negative."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "441 559\n"
     ]
    }
   ],
   "source": [
    "pos, neg = 0, 0\n",
    "for review in pos_reviews:\n",
    "    if(review[0] != 'c'):\n",
    "        continue\n",
    "    score = sumScores('data/review_polarity/txt_sentoken/pos/'+review)\n",
    "    if(score[0] > score[1]):\n",
    "        pos += 1\n",
    "    else:\n",
    "        neg +=1\n",
    "print(pos, neg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On a thousand positive reviews, 441 are marked as positive and 559 as negative. \n",
    "\n",
    "We can see that this technique is not accurate at all. The objective now is to find a threshold between the positive score and the negative score that will give more accurate results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
